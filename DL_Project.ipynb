{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sairohitt18/Deep-Learning-Lung-Cancer-Detection/blob/main/DL_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WztLXTFEpe2M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "import cv2\n",
        "import gc\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QsQktCK2S5m",
        "outputId": "d245b70f-de14-4223-81be-811c3891d4cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The data set has been extracted.\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "data_path = 'lung-and-colon-cancer-histopathological-images.zip'\n",
        "\n",
        "with ZipFile(data_path,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The data set has been extracted.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygu1rt7tplN-",
        "outputId": "5b9449ba-f58a-4d8c-ad58-0de6a4ae2106"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['lung_n', 'lung_scc', 'lung_aca']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = 'lung_colon_image_set/lung_image_sets'\n",
        "classes = os.listdir(path)\n",
        "classes\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'lung_colon_image_set/lung_image_sets'\n",
        "\n",
        "for cat in classes:\n",
        "\timage_dir = f'{path}/{cat}'\n",
        "\timages = os.listdir(image_dir)\n",
        "\n",
        "\tfig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\tfig.suptitle(f'Images for {cat} category . . . .', fontsize=20)\n",
        "\n",
        "\tfor i in range(3):\n",
        "\t\tk = np.random.randint(0, len(images))\n",
        "\t\timg = np.array(Image.open(f'{path}/{cat}/{images[k]}'))\n",
        "\t\tax[i].imshow(img)\n",
        "\t\tax[i].axis('off')\n",
        "\tplt.show()"
      ],
      "metadata": {
        "id": "Gj3bztS4nwy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afnDnXBOpplI"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 256\n",
        "SPLIT = 0.2\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lOcqHfxBpuGZ"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "Y = []\n",
        "\n",
        "for i, cat in enumerate(classes):\n",
        "\timages = glob(f'{path}/{cat}/*.jpeg')\n",
        "\n",
        "for image in images:\n",
        "\timg = cv2.imread(image)\n",
        "\t\n",
        "\tX.append(cv2.resize(img, (IMG_SIZE, IMG_SIZE)))\n",
        "\tY.append(i)\n",
        "\n",
        "X = np.asarray(X)\n",
        "one_hot_encoded_Y = pd.get_dummies(Y).values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Rn8t3Kgpxc7"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(X, one_hot_encoded_Y,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\ttest_size = SPLIT,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\trandom_state = 2022)\n",
        "print(X_train.shape, X_val.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojVTFWARp1cr"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "\tlayers.Conv2D(filters=32,\n",
        "\t\t\t\tkernel_size=(5, 5),\n",
        "\t\t\t\tactivation='relu',\n",
        "\t\t\t\tinput_shape=(IMG_SIZE,\n",
        "\t\t\t\t\t\t\tIMG_SIZE,\n",
        "\t\t\t\t\t\t\t3),\n",
        "\t\t\t\tpadding='same'),\n",
        "\tlayers.MaxPooling2D(2, 2),\n",
        "\n",
        "\tlayers.Conv2D(filters=64,\n",
        "\t\t\t\tkernel_size=(3, 3),\n",
        "\t\t\t\tactivation='relu',\n",
        "\t\t\t\tpadding='same'),\n",
        "\tlayers.MaxPooling2D(2, 2),\n",
        "\n",
        "\tlayers.Conv2D(filters=128,\n",
        "\t\t\t\tkernel_size=(3, 3),\n",
        "\t\t\t\tactivation='relu',\n",
        "\t\t\t\tpadding='same'),\n",
        "\tlayers.MaxPooling2D(2, 2),\n",
        "\n",
        "\tlayers.Flatten(),\n",
        "\tlayers.Dense(256, activation='relu'),\n",
        "\tlayers.BatchNormalization(),\n",
        "\tlayers.Dense(128, activation='relu'),\n",
        "\tlayers.Dropout(0.3),\n",
        "\tlayers.BatchNormalization(),\n",
        "\tlayers.Dense(3, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6bnzlu1p5wd"
      },
      "outputs": [],
      "source": [
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVqQ9AgPp9C3"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(\n",
        "\tmodel,\n",
        "\tshow_shapes = True,\n",
        "\tshow_dtype = True,\n",
        "\tshow_layer_activations = True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOOjCUpfqBBB"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "\toptimizer = 'adam',\n",
        "\tloss = 'categorical_crossentropy',\n",
        "\tmetrics = ['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb4Tk4NbqHAP"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\tif logs.get('val_accuracy') > 0.90:\n",
        "\t\t\tprint('\\n Validation accuracy has reached upto \\\n",
        "\t\t\t\t\t90% so, stopping further training.')\n",
        "\t\t\tself.model.stop_training = True\n",
        "\n",
        "\n",
        "es = EarlyStopping(patience=3,\n",
        "\t\t\t\tmonitor='val_accuracy',\n",
        "\t\t\t\trestore_best_weights=True)\n",
        "\n",
        "lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "\t\t\t\t\tpatience=2,\n",
        "\t\t\t\t\tfactor=0.5,\n",
        "\t\t\t\t\tverbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6YwRjNbqKsp"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, Y_train,\n",
        "\t\t\t\t\tvalidation_data = (X_val, Y_val),\n",
        "\t\t\t\t\tbatch_size = BATCH_SIZE,\n",
        "\t\t\t\t\tepochs = EPOCHS,\n",
        "\t\t\t\t\tverbose = 1,\n",
        "\t\t\t\t\tcallbacks = [es, lr, myCallback()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQssYtZ2qOrC"
      },
      "outputs": [],
      "source": [
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.loc[:,['loss','val_loss']].plot()\n",
        "history_df.loc[:,['accuracy','val_accuracy']].plot()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve_aeobNqRo6"
      },
      "outputs": [],
      "source": [
        "Y_pred = model.predict(X_val)\n",
        "Y_val = np.argmax(Y_val, axis=1)\n",
        "Y_pred = np.argmax(Y_pred, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SH5po-YUqWuD"
      },
      "outputs": [],
      "source": [
        "metrics.confusion_matrix(Y_val, Y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0koGvNHqY9n"
      },
      "outputs": [],
      "source": [
        "print(metrics.classification_report(Y_val, Y_pred,\n",
        "\t\t\t\t\t\t\t\t\ttarget_names=classes))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTdk+ctkkaxKRPn6uyVVja",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}